{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 level Ensemble of Light Pyramidal 1D CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qOIKN397TkGK",
        "sePFuqjSSzzW",
        "1KwvTxntVWdO",
        "Y-zRwIXuE1Dw",
        "XZCzWyC3E0LE",
        "y_iMln5YFpPm",
        "qW2H4bC0F8i1",
        "dMaxASVXGRtj",
        "MbLBgzu2hLKh",
        "r4lu2licKkgB"
      ],
      "authorship_tag": "ABX9TyNrrtkcDnhBZwSfYuKxGlyP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vipulSharma18/Automatic-Emotion-Recognition-on-DEAP-Dataset/blob/main/2_level_Ensemble_of_Light_Pyramidal_1D_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOIKN397TkGK"
      },
      "source": [
        "# Add Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAkhHc84RFps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2c182e6-c6af-46b6-c321-ce51c5c1d801"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sePFuqjSSzzW"
      },
      "source": [
        "# Importing Relevant Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKto0bShTo8Q"
      },
      "source": [
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import tensorflow.keras as keras\r\n",
        "from tensorflow.keras import Sequential\r\n",
        "from tensorflow.keras.layers import Conv1D\r\n",
        "from tensorflow.keras.layers import MaxPooling1D\r\n",
        "from tensorflow.keras.layers import Flatten\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "from tensorflow.keras.layers import Softmax\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from keras.utils.vis_utils import plot_model\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pickle\r\n",
        "from scipy.stats import zscore\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s62df0ZsoV3v"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KwvTxntVWdO"
      },
      "source": [
        "# GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_-_kIr3VPbW",
        "outputId": "ee229947-eb1c-4329-bf63-2fcd84595d99"
      },
      "source": [
        "print(tf.version.VERSION)\r\n",
        "print(tf.config.experimental.list_physical_devices('GPU'))\r\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "[]\n",
            "Num GPUs Available:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUGKR7rKALkc"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-zRwIXuE1Dw"
      },
      "source": [
        "## Load Data from .dat files into a np array of 1280 x 32 x 8064 size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBrvJXFLVXfY"
      },
      "source": [
        "all_sub_data = []\r\n",
        "subjects_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32']\r\n",
        "for sub in subjects_list:\r\n",
        "    path = \"/content/drive/MyDrive/major project/data_preprocessed_python/s\"+sub+\".dat\"\r\n",
        "    x = pickle.load(open(path, 'rb'), encoding = 'latin1')\r\n",
        "    sub_data = x['data']\r\n",
        "    sub_eeg = sub_data[:, :32, :]  #indexing EEG signals from physiological data\r\n",
        "    all_sub_data.extend(sub_eeg)\r\n",
        "all_sub_data = np.array(all_sub_data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQDfrbarAEEM",
        "outputId": "37cb6789-275c-47ee-c30c-73d4d42a375e"
      },
      "source": [
        "all_sub_data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1280, 32, 8064)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZCzWyC3E0LE"
      },
      "source": [
        "## Z-score normalization of each EEG signal, resultant np.array is all_sub_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k0v3c0CAa37"
      },
      "source": [
        "for sub in range(all_sub_data.shape[0]):\r\n",
        "  all_sub_data[sub] = zscore(all_sub_data[sub], axis = 1)  #zscore normalize each channel"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_iMln5YFpPm"
      },
      "source": [
        "## Label Loading into np array of 1280 x 1 named, sub_labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSkKkHMSExMw",
        "outputId": "e0507e75-0343-4e5e-b38c-ba1d7e815c53"
      },
      "source": [
        "labels = pd.read_excel(\"/content/drive/MyDrive/major project/metadata/Labels.xls\")\r\n",
        "sub_labels = labels[\"Valence-Arousal Model Quadrant\"].astype('int')\r\n",
        "sub_labels"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       3\n",
              "1       3\n",
              "2       3\n",
              "3       1\n",
              "4       2\n",
              "       ..\n",
              "1275    1\n",
              "1276    1\n",
              "1277    1\n",
              "1278    1\n",
              "1279    2\n",
              "Name: Valence-Arousal Model Quadrant, Length: 1280, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW2H4bC0F8i1"
      },
      "source": [
        "## One-Hot encoding of labels  \r\n",
        "> sub_labels: (1280,4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS2wFxlQFtrh",
        "outputId": "1613a8ca-a0d0-426f-9ba6-5bd6acc6c0c8"
      },
      "source": [
        "lb = preprocessing.LabelBinarizer()\r\n",
        "sub_labels = lb.fit_transform(sub_labels)\r\n",
        "print(lb.classes_)\r\n",
        "print(sub_labels.shape)\r\n",
        "print(sub_labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3]\n",
            "(1280, 4)\n",
            "[[0 0 0 1]\n",
            " [0 0 0 1]\n",
            " [0 0 0 1]\n",
            " ...\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm3vZbEbGMmd",
        "outputId": "c886fdeb-e4af-4ae8-dc41-46b03b96212b"
      },
      "source": [
        "sub_labels.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1280, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BKGgYS1GOqz"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMaxASVXGRtj"
      },
      "source": [
        "## Generating Train Test Splits,  \r\n",
        "> X_train, y_train: (1152,32,8064), (1152,4)  \r\n",
        "> X_test, y_test: (128,32,8064), (128,4)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jLCp18rGVuh"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(all_sub_data, sub_labels, test_size = 0.1, random_state = 42,shuffle = True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rzb207S6IimP",
        "outputId": "54c444c7-74cd-4b4b-a2b1-ac67fafb3c43"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1152, 32, 8064), (1152, 4), (128, 32, 8064), (128, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6306xrqyIoni"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbLBgzu2hLKh"
      },
      "source": [
        "## Repetition of Labels for Windowing of training data  \r\n",
        "\r\n",
        "> y_train_12, y_train_6, y_train_4 of shapes(?,4): 13824, 6912 and 4608 respectively \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kZRCXm-d0Oj",
        "outputId": "27d985d1-165f-4407-fa5d-c201ddd4f0d5"
      },
      "source": [
        "#12,6 and 4 subsignals are generated from 8064 length EEG signal, labels repeated accordingly\r\n",
        "y_train_12 = np.repeat(y_train, 12, axis = 0)\r\n",
        "y_train_6 = np.repeat(y_train, 6, axis = 0)\r\n",
        "y_train_4 = np.repeat(y_train, 4, axis = 0)\r\n",
        "print(y_train_12.shape, y_train_6.shape, y_train_4.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13824, 4) (6912, 4) (4608, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDYiz9Gshkih"
      },
      "source": [
        "## Windowing of EEG singals Channel wise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wVHirSWYuVQ"
      },
      "source": [
        "Channel_wise = np.transpose(X_train, (1,0,2))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nugeg0kgoh00",
        "outputId": "76a895c3-c4c1-4bc8-f076-d3a4fcf6d225"
      },
      "source": [
        "print(Channel_wise[0].shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1152, 8064)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El4sFpkcyh24"
      },
      "source": [
        "def process_input(instances, sub_signals):\r\n",
        "  #instances must be channel wise of shape (32, -1, 8064)\r\n",
        "  samples = int(8064/sub_signals)\r\n",
        "  transformed = []\r\n",
        "  for i in range(instances.shape[0]):\r\n",
        "    transformed.append(np.reshape(instances[i], (-1,672,1)))\r\n",
        "  transformed = np.array(transformed)\r\n",
        "  print(transformed.shape, 'is the shape obtained.')\r\n",
        "  return transformed"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAf6zyrW2QO9",
        "outputId": "16f70730-f54b-440f-8234-395fb8a95c62"
      },
      "source": [
        "channel_wise_12 = process_input(Channel_wise, 12)\r\n",
        "print(channel_wise_12.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 13824, 672, 1) is the shape obtained.\n",
            "(32, 13824, 672, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUCB6L7r3NCw"
      },
      "source": [
        "channel_wise_6 = process_input(Channel_wise, 6)\r\n",
        "channel_wise_4 = process_input(Channel_wise, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4lu2licKkgB"
      },
      "source": [
        "# Lightweight Pyramidal 1D CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puI2iRNDKpaW"
      },
      "source": [
        "def create_models(dense_par=20, sub_signals=12):\r\n",
        "  sample_size = int(8064/sub_signals)\r\n",
        "  models = [0]*32\r\n",
        "  for i in range(32):\r\n",
        "    models[i] = Sequential()\r\n",
        "    models[i].add(Conv1D(filters=32, kernel_size=5,strides = 3, input_shape=(sample_size, 1)))\r\n",
        "    models[i].add(BatchNormalization())\r\n",
        "    models[i].add(tf.keras.layers.Activation('relu'))\r\n",
        "    models[i].add(Conv1D(filters=24, kernel_size=3,strides = 2))\r\n",
        "    models[i].add(BatchNormalization())\r\n",
        "    models[i].add(tf.keras.layers.Activation('relu'))\r\n",
        "    models[i].add(Conv1D(filters=16, kernel_size=3,strides = 2))\r\n",
        "    models[i].add(BatchNormalization())\r\n",
        "    models[i].add(tf.keras.layers.Activation('relu'))\r\n",
        "    models[i].add(Conv1D(filters=8, kernel_size=3,strides = 2))\r\n",
        "    models[i].add(BatchNormalization())\r\n",
        "    models[i].add(tf.keras.layers.Activation('relu'))\r\n",
        "    models[i].add(Flatten())\r\n",
        "    models[i].add(Dense(dense_par, activation='relu'))\r\n",
        "    models[i].add(Dropout(rate = 0.5))\r\n",
        "    models[i].add(Dense(4, activation = 'softmax'))\r\n",
        "    models[i].compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.0001,beta_1=0.9,beta_2=0.999,epsilon=1e-08) , loss = tf.keras.losses.CategoricalCrossentropy(), metrics= 'accuracy')\r\n",
        "  return models"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}