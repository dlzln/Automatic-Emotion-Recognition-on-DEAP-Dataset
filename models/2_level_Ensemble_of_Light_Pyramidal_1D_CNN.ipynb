{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 level Ensemble of Light Pyramidal 1D CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vipulSharma18/Automatic-Emotion-Recognition-on-DEAP-Dataset/blob/main/models/2_level_Ensemble_of_Light_Pyramidal_1D_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsEFk_SV7EH6",
        "outputId": "2bfbfaaf-3e3b-4be9-eafe-76c4edc809c9"
      },
      "source": [
        "inp_choice = input(\"Enter b for Binary, m for Multi-Class Classification: \")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter b for Binary, m for Multi-Class Classification: b\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOIKN397TkGK"
      },
      "source": [
        "# Add Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAkhHc84RFps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e085d0-152c-43af-b174-5df99be88953"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sePFuqjSSzzW"
      },
      "source": [
        "# Importing Relevant Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKto0bShTo8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e8e30de-d245-4530-ec15-bb498626bc31"
      },
      "source": [
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import tensorflow.keras as keras\r\n",
        "from tensorflow.keras import Sequential\r\n",
        "from tensorflow.keras.layers import Conv1D\r\n",
        "from tensorflow.keras.layers import MaxPooling1D\r\n",
        "from tensorflow.keras.layers import Flatten\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "from tensorflow.keras.layers import Softmax\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from keras.utils.vis_utils import plot_model\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pickle\r\n",
        "from scipy.stats import zscore\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn import preprocessing\r\n",
        "import gc\r\n",
        "from keras.callbacks import ReduceLROnPlateau\r\n",
        "from collections import Counter\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.utils.class_weight import compute_class_weight\r\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K99-9l0UZ2vG"
      },
      "source": [
        "RANDOM_SEED = 42\r\n",
        "tf.random.set_seed(RANDOM_SEED)\r\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KwvTxntVWdO"
      },
      "source": [
        "# GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_-_kIr3VPbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ce024c-20da-4993-f16f-bf35f772f8eb"
      },
      "source": [
        "print(tf.version.VERSION)\r\n",
        "print(tf.config.experimental.list_physical_devices('GPU'))\r\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "[]\n",
            "Num GPUs Available:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUGKR7rKALkc"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-zRwIXuE1Dw"
      },
      "source": [
        "## Load Data from .dat files into a np array of 1280 x 32 x 8064 size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBrvJXFLVXfY"
      },
      "source": [
        "#Uncomment Below Code if need to Reload all data from scratch\r\n",
        "\"\"\"\r\n",
        "all_sub_data = []\r\n",
        "subjects_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32']\r\n",
        "for sub in subjects_list:\r\n",
        "    path = \"/content/drive/MyDrive/major project/data_preprocessed_python/s\"+sub+\".dat\"\r\n",
        "    x = pickle.load(open(path, 'rb'), encoding = 'latin1')\r\n",
        "    sub_data = x['data']\r\n",
        "    sub_eeg = sub_data[:, :32, :]  #indexing EEG signals from physiological data\r\n",
        "    all_sub_data.extend(sub_eeg)\r\n",
        "    gc.collect()\r\n",
        "gc.collect()\r\n",
        "all_sub_data = np.array(all_sub_data)\r\n",
        "\"\"\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQDfrbarAEEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c1a955-d076-4d9b-d240-104d06686efa"
      },
      "source": [
        "all_sub_data = np.load(\"/content/drive/MyDrive/major project/all_sub_data.npy\")\r\n",
        "print(all_sub_data.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1280, 32, 8064)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZCzWyC3E0LE"
      },
      "source": [
        "## Z-score normalization of each EEG signal, resultant np.array is all_sub_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k0v3c0CAa37"
      },
      "source": [
        "for sub in range(all_sub_data.shape[0]):\r\n",
        "  all_sub_data[sub] = zscore(all_sub_data[sub], axis = 1)  #zscore normalize each channel\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_iMln5YFpPm"
      },
      "source": [
        "## Label Loading into np array of 1280 x 1 named, sub_labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyBCVoGi8dcy"
      },
      "source": [
        "if(inp_choice == 'm'):\r\n",
        "  labels = pd.read_excel(\"/content/drive/MyDrive/major project/metadata/Labels.xls\")\r\n",
        "  #for multiclass classification \r\n",
        "  sub_labels = labels[\"Valence-Arousal Model Quadrant\"].astype('int')\r\n",
        "  gc.collect()\r\n",
        "  sub_labels\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSkKkHMSExMw"
      },
      "source": [
        "if(inp_choice == 'b'):\r\n",
        "  labels = pd.read_excel(\"/content/drive/MyDrive/major project/metadata/Labels.xls\")\r\n",
        "  #for binary classification of valence scale\r\n",
        "  sub_labels = labels[\"Valence Label (1=H, 0=L)\"].astype('int')\r\n",
        "  gc.collect()\r\n",
        "  sub_labels\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrtZQana8vAV"
      },
      "source": [
        "Distribution of Multi-Class Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzmz94HIBx6S"
      },
      "source": [
        "if(inp_choice == 'm'):\r\n",
        "  #SKIP FOR BINARY CLASSIFICATION\r\n",
        "  # Add frequency bar plot here for dataset label distribution\r\n",
        "  c = Counter(sub_labels)\r\n",
        "  print(c)\r\n",
        "  plt.figure()\r\n",
        "  plt.bar([0,1,2,3], [c[0], c[1], c[2], c[3]])\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWpejG3M8y9p"
      },
      "source": [
        "Distribution of Binary Class Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGVYTpM882YG"
      },
      "source": [
        "if(inp_choice == 'b'):\r\n",
        "  # Add frequency bar plot here for dataset label distribution\r\n",
        "  c = Counter(sub_labels)\r\n",
        "  print(c)\r\n",
        "  plt.figure()\r\n",
        "  plt.bar([0,1], [c[0], c[1]])\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW2H4bC0F8i1"
      },
      "source": [
        "## Label Binarization of multi-class labels  \r\n",
        "> sub_labels: (1280,4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fhzB0RM9XmV"
      },
      "source": [
        "if(inp_choice == 'm'):\r\n",
        "  multi_class_weights = compute_class_weights(\"balanced\", classes = [0,1,2,3], y=sub_labels)\r\n",
        "  print(multi_class_weights)\r\n",
        "  d_multi_class_weights = dict(enumerate(multi_class_weights))\r\n",
        "  print(d_multi_class_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS2wFxlQFtrh"
      },
      "source": [
        "if(inp_choice == 'm'):\r\n",
        "  lb = preprocessing.LabelBinarizer()\r\n",
        "  sub_labels = lb.fit_transform(sub_labels)\r\n",
        "  print(lb.classes_)\r\n",
        "  print(sub_labels.shape)\r\n",
        "  print(sub_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BKGgYS1GOqz"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXpIgG-QGtUN"
      },
      "source": [
        "if(inp_choice == 'm'):\r\n",
        "  np.unique(sub_labels, axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvc1s7V6u7KM"
      },
      "source": [
        "## Label Binarization of 2/Binary labels  \r\n",
        "> sub_labels: (1280,2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9784GX9zwMq0"
      },
      "source": [
        "sub_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDBM9Cui8nHf"
      },
      "source": [
        "if(inp_choice == 'b'):\r\n",
        "  bin_class_weights = compute_class_weight(\"balanced\", classes = [0,1], y=sub_labels)\r\n",
        "  print(bin_class_weights)\r\n",
        "  d_bin_class_weights = dict(enumerate(bin_class_weights))\r\n",
        "  print(d_bin_class_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un8vJezHu2CR"
      },
      "source": [
        "def encode(x):\r\n",
        "  if(x==1):\r\n",
        "    return [0,1]\r\n",
        "  elif(x==0):\r\n",
        "    return [1,0]\r\n",
        "  else:\r\n",
        "    print(\"invalid value\")\r\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ8uaRF-q9BJ"
      },
      "source": [
        "if(inp_choice == 'b'):\r\n",
        "  sub_labels_bin = np.array(list(map(encode, sub_labels)))\r\n",
        "  print(sub_labels_bin.shape)\r\n",
        "  print(sub_labels_bin[:6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5neiC9SuyDIv"
      },
      "source": [
        "if(inp_choice == 'b'):\r\n",
        "  sub_labels_bin[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y7jHr_QyYfJ"
      },
      "source": [
        "if(inp_choice == 'b'):\r\n",
        "  sub_labels = sub_labels_bin\r\n",
        "  gc.collect()\r\n",
        "  print(sub_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3ctIDjx47eA"
      },
      "source": [
        "def inv_bin(x):\r\n",
        "  if(x == [0,1]):\r\n",
        "     return 1\r\n",
        "  elif(x==[1,0]):\r\n",
        "    return 0\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMaxASVXGRtj"
      },
      "source": [
        "## Generating Train Test Splits  \r\n",
        "> X_train, y_train: (1152,32,8064), (1152,4)  \r\n",
        "> X_test, y_test: (128,32,8064), (128,4)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jLCp18rGVuh"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(all_sub_data, sub_labels, test_size = 0.1, random_state = 42,shuffle = True, stratify = sub_labels)\r\n",
        "#TO DO:\r\n",
        "#Check if class imbalance in the splits exists and is severe than the dataset\r\n",
        "#use stratify = y_labels to ensure same distribution as dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzb207S6IimP"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6306xrqyIoni"
      },
      "source": [
        "try:\r\n",
        "  del all_sub_data\r\n",
        "  del sub_labels\r\n",
        "  del labels\r\n",
        "  del x\r\n",
        "  del sub_data\r\n",
        "  del sub_eeg\r\n",
        "  del subjects_list\r\n",
        "except:\r\n",
        "  pass\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbLBgzu2hLKh"
      },
      "source": [
        "## Repetition of Labels for Windowing of training data  \r\n",
        "\r\n",
        "> y_train_12, y_train_6, y_train_4 of shapes(?,4): 13824, 6912 and 4608 respectively \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs4hjPnQBevY"
      },
      "source": [
        "y_train = np.array(y_train)\r\n",
        "print(y_train.shape, type(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kZRCXm-d0Oj"
      },
      "source": [
        "#12,6 and 4 subsignals are generated from 8064 length EEG signal, labels repeated accordingly\r\n",
        "y_train_12 = np.repeat(y_train, 12, axis = 0)\r\n",
        "#y_train_6 = np.repeat(y_train, 6, axis = 0)\r\n",
        "#y_train_4 = np.repeat(y_train, 4, axis = 0)\r\n",
        "del(y_train)\r\n",
        "gc.collect()\r\n",
        "#print(y_train_12.shape, y_train_6.shape, y_train_4.shape)\r\n",
        "print(y_train_12.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o3-c92KKIEw"
      },
      "source": [
        "try:\r\n",
        "  del y_train_6, y_train_4\r\n",
        "except:\r\n",
        "  pass\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90bC-ViKLIxC"
      },
      "source": [
        "try:\r\n",
        "  del c_train, c_test, c_train_12, c\r\n",
        "except:\r\n",
        "  pass\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHs7gtIiCSzm"
      },
      "source": [
        "## Loading Training data with different window sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VrZ1ZprCpy8"
      },
      "source": [
        "channel_wise = np.transpose(X_train, (1,0,2))\r\n",
        "del(X_train)\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWq2RDpQCmm7"
      },
      "source": [
        "\r\n",
        "def process_input(instances, sub_signals):\r\n",
        "  #instances must be channel wise of shape (32, -1, 8064)\r\n",
        "  samples = int(8064/sub_signals)\r\n",
        "  transformed = []\r\n",
        "  for i in range(instances.shape[0]):\r\n",
        "    transformed.append(np.reshape(instances[i], (-1,samples,1)))\r\n",
        "  transformed = np.array(transformed)\r\n",
        "  print(transformed.shape, 'is the shape obtained.')\r\n",
        "  gc.collect()\r\n",
        "  return transformed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8JkC-thgX70"
      },
      "source": [
        "### 12 sub signals of length 672 each, total 13824 instances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAf6zyrW2QO9"
      },
      "source": [
        "#X_train_12 = np.load(\"/content/drive/MyDrive/major project/data_augmentation/channel_wise_12.npy\")\r\n",
        "#print(X_train_12.shape, 'Shape of Training Data')\r\n",
        "X_train_12 = process_input(channel_wise, 12)\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcQGE_1Cggo8"
      },
      "source": [
        "### 6 sub signals of length 1344 each, total 6912 instances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUCB6L7r3NCw"
      },
      "source": [
        "#X_train_6 = np.load(\"/content/drive/MyDrive/major project/data_augmentation/channel_wise_6.npy\")\r\n",
        "#print(X_train_6.shape, 'Shape of Training Data')\r\n",
        "#gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5MiX9c3goCv"
      },
      "source": [
        "### 4 sub signals of length 2016 each, total 4608 instances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLdrXz4Re7yQ"
      },
      "source": [
        "#X_train_4 = np.load(\"/content/drive/MyDrive/major project/data_augmentation/channel_wise_4.npy\")\r\n",
        "#print(X_train_4.shape, 'Shape of Training Data')\r\n",
        "#gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dIg_b-_W7ZD"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9lcKzmxL-SB"
      },
      "source": [
        "Free Up ram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a0RzGPOL6WY"
      },
      "source": [
        "del channel_wise\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDYiz9Gshkih"
      },
      "source": [
        "## Preprocessing for passing test data into CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El4sFpkcyh24"
      },
      "source": [
        "def process_input_ensemble(instances, sub_signals):\r\n",
        "  \"\"\"\r\n",
        "  This Function explicity adds a dimension for the sub_signals, hence is used for ensembel modeling to traverse that dimension.\r\n",
        "  Otherwise also we can simply assume, since the dataset is ordered that the groups of len(sub_signals) are obtained from one EEG signal\r\n",
        "  \"\"\"\r\n",
        "  #instances must be channel wise of shape (32, -1, 8064)\r\n",
        "  gc.collect()\r\n",
        "  samples = int(8064/sub_signals)\r\n",
        "  transformed = []\r\n",
        "  for i in range(instances.shape[0]):\r\n",
        "    transformed.append(np.reshape(instances[i], (-1,sub_signals,samples,1)))\r\n",
        "    gc.collect()\r\n",
        "  transformed = np.array(transformed)\r\n",
        "  print(transformed.shape, 'is the shape obtained.')\r\n",
        "  gc.collect()\r\n",
        "  #output shape will be (len(intances), 32, sub_signals, samples, 1)\r\n",
        "  return transformed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sRlglOSyqBD"
      },
      "source": [
        "For Channel Wise Evaluation and Not Ensemble Evaluation, below can be used.  \r\n",
        "(* This can also be used for ensemble if we explicitly group len(sub_signals) samples together to represent 1 EEG signal, remember to do no shuffling in this case)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu2211LFLhx8"
      },
      "source": [
        "X_test_channels = np.transpose(X_test, (1,0,2))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLEiRYcx4Uwn"
      },
      "source": [
        "12 sub_signals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOwz_7kI4Txj"
      },
      "source": [
        "x_test_12 = process_input(X_test_channels, 12)\r\n",
        "y_test_12 = np.repeat(np.array(y_test), 12, axis = 0)\r\n",
        "print(x_test_12.shape, y_test_12.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZzrV9In4iQQ"
      },
      "source": [
        "6 sub_signals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY73YEgd4XgX"
      },
      "source": [
        "x_test_6 = process_input(X_test_channels, 6)\r\n",
        "y_test_6 = np.repeat(np.array(y_test), 6, axis = 0)\r\n",
        "print(x_test_6.shape, y_test_6.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_fGNb6h4kIh"
      },
      "source": [
        "4 sub_signals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fag1SGJ84XP6"
      },
      "source": [
        "x_test_4 = process_input(X_test_channels, 4)\r\n",
        "y_test_4 = np.repeat(np.array(y_test), 4, axis = 0)\r\n",
        "print(x_test_4.shape, y_test_4.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj3M5HbaRn-x"
      },
      "source": [
        "## Problem of Class imbalance:  \r\n",
        "The model is biased towards a class due to class imbalance and is not fitting the data. The class {3} is majority class with around 35% samples in train, test and original dataset\r\n",
        "due to stratified sampling. The model accuracy is also around 35% which clearly indicated majority voting is being done and no learning. Further we created a confusion matrix for training and validation sets which confirms this hypothesis.\r\n",
        "\r\n",
        "Solutions:\r\n",
        "1. Use class weighing in model.fit, weightI = total/Instances_I, inverse frequency or n_samples / (n_classes * np.bincount(y))\r\n",
        "2. Undersampling: `from sklearn.utils import resample  \r\n",
        "no_claim_downsampled = resample(no_claim,replace = False,n_samples = len(claim), random_state = RANDOM_SEED)`    \r\n",
        "3. Oversampling:  `claim_upsampled = resample(claim, replace=True, n_samples=len(no_claim), random_state=RANDOM_SEED)`  \r\n",
        "4. Synthetic Sample Generation with SMOTE:   \r\n",
        "` from imblearn.over_sampling import SMOTE  \r\n",
        "sm = SMOTE(random_state=RANDOM_SEED, ratio=1.0)  \r\n",
        "X_train, y_train = sm.fit_sample(X_train, y_train)`  \r\n",
        "5. Metrics: Precision is the percentage of predicted positives that were correctly classified.  \r\n",
        "Recall is the percentage of actual positives that were correctly classified.  \r\n",
        "AUC refers to the Area Under the Curve of a Receiver Operating Characteristic curve (ROC-AUC). This metric is equal to the probability that a classifier will rank a random positive sample higher than a random negative sample.  \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4lu2licKkgB"
      },
      "source": [
        "# Models Fitting and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55wVi_i3sOva"
      },
      "source": [
        "## Helper Functions for plotting, confusion matrix etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dfAn7kZrqJ5"
      },
      "source": [
        "def plot_evaluation_curves(history, EPOCHS, metrics = ('accuracy', 'val_accuracy')):\r\n",
        "  acc = history.history[metrics[0]]\r\n",
        "  val_acc = history.history[metrics[1]]\r\n",
        "\r\n",
        "  loss = history.history['loss']\r\n",
        "  val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "  epochs_range = range(EPOCHS)\r\n",
        "\r\n",
        "  plt.figure(figsize=(10, 6))\r\n",
        "  plt.subplot(1, 2, 1)\r\n",
        "  plt.plot(epochs_range, acc, label='Training ' + metrics[0])\r\n",
        "  plt.plot(epochs_range, val_acc, label='Validation '+ metrics[0])\r\n",
        "  plt.legend(loc='lower right')\r\n",
        "  plt.title('Training and Validation ' +  metrics[0])\r\n",
        "\r\n",
        "  plt.subplot(1, 2, 2)\r\n",
        "  plt.plot(epochs_range, loss, label='Training Loss')\r\n",
        "  plt.plot(epochs_range, val_loss, label='Validation Loss')\r\n",
        "  plt.legend(loc='upper right')\r\n",
        "  plt.title('Training and Validation Loss')\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP1Z7uSCldBE"
      },
      "source": [
        "def make_confusion_matrix(cf,\r\n",
        "                          group_names=None,\r\n",
        "                          categories='auto',\r\n",
        "                          count=True,\r\n",
        "                          percent=True,\r\n",
        "                          cbar=True,\r\n",
        "                          xyticks=True,\r\n",
        "                          xyplotlabels=True,\r\n",
        "                          sum_stats=True,\r\n",
        "                          figsize=None,\r\n",
        "                          cmap='Blues',\r\n",
        "                          title=None):\r\n",
        "    '''\r\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\r\n",
        "    Arguments\r\n",
        "    ---------\r\n",
        "    cf:            confusion matrix to be passed in\r\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\r\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\r\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\r\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\r\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\r\n",
        "                   Default is True.\r\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\r\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\r\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\r\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\r\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\r\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\r\n",
        "                   \r\n",
        "    title:         Title for the heatmap. Default is None.\r\n",
        "    '''\r\n",
        "\r\n",
        "\r\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\r\n",
        "    blanks = ['' for i in range(cf.size)]\r\n",
        "\r\n",
        "    if group_names and len(group_names)==cf.size:\r\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\r\n",
        "    else:\r\n",
        "        group_labels = blanks\r\n",
        "\r\n",
        "    if count:\r\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\r\n",
        "    else:\r\n",
        "        group_counts = blanks\r\n",
        "\r\n",
        "    if percent:\r\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\r\n",
        "    else:\r\n",
        "        group_percentages = blanks\r\n",
        "\r\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\r\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\r\n",
        "\r\n",
        "\r\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\r\n",
        "    if sum_stats:\r\n",
        "        #Accuracy is sum of diagonal divided by total observations\r\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\r\n",
        "\r\n",
        "        #if it is a binary confusion matrix, show some more stats\r\n",
        "        if len(cf)==2:\r\n",
        "            #Metrics for Binary Confusion Matrices\r\n",
        "            precision = cf[1,1] / sum(cf[:,1])\r\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\r\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\r\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\r\n",
        "                accuracy,precision,recall,f1_score)\r\n",
        "        else:\r\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\r\n",
        "    else:\r\n",
        "        stats_text = \"\"\r\n",
        "\r\n",
        "\r\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\r\n",
        "    if figsize==None:\r\n",
        "        #Get default figure size if not set\r\n",
        "        figsize = plt.rcParams.get('figure.figsize')\r\n",
        "\r\n",
        "    if xyticks==False:\r\n",
        "        #Do not show categories if xyticks is False\r\n",
        "        categories=False\r\n",
        "\r\n",
        "\r\n",
        "    # MAKE THE HEATMAP VISUALIZATION\r\n",
        "    plt.figure(figsize=figsize)\r\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\r\n",
        "\r\n",
        "    if xyplotlabels:\r\n",
        "        plt.ylabel('True label')\r\n",
        "        plt.xlabel('Predicted label' + stats_text)\r\n",
        "    else:\r\n",
        "        plt.xlabel(stats_text)\r\n",
        "    \r\n",
        "    if title:\r\n",
        "        plt.title(title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH3xTl2w4E_c"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcgN8lB-Tjzc"
      },
      "source": [
        "### Checking the distribution of predicted labels to check if majority class voting being done or Model is actually learning\r\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYFLgNU0orVO"
      },
      "source": [
        "def show_test_metrics(x_test, y_test, model):\r\n",
        "  print(\"Testing Set MEASURES: \")\r\n",
        "  #Testing Data metrics\r\n",
        "  pred_y = model.predict(x_test)\r\n",
        "  c_pred = Counter(np.argmax(pred_y, axis = 1))\r\n",
        "  print(c_pred, \"Predicted Distribution of Testing Dataset\")\r\n",
        "  c_true = Counter(np.argmax(y_test, axis = 1))\r\n",
        "  print(c_true, \"Actual Distribution of Testing Dataset\")\r\n",
        "  print(model.evaluate(x_test, y_test), \"Testing Measures of Model.\")\r\n",
        "  print(\"Classification Report of Model on Testing Data\")\r\n",
        "  print(classification_report(np.argmax(y_test, axis =1), np.argmax(model.predict(x_test), axis = 1) , digits = 4) )\r\n",
        "  make_confusion_matrix(confusion_matrix(np.argmax(y_test, axis = 1), np.argmax(model.predict(x_test), axis = 1)))\r\n",
        "  print(\"------------------------------------------------------------\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGcCyM-7ngan"
      },
      "source": [
        "def show_metrics(x_train=None, x_val=None, y_train=None, y_val=None, model=None):\n",
        "  print(\"TRAINING MEASURES: \")\n",
        "  #Training Data metrics\n",
        "  pred_y = model.predict(x_train)\n",
        "  c_pred = Counter(np.argmax(pred_y, axis = 1))\n",
        "  print(c_pred, \"Predicted Distribution of Training Dataset\")\n",
        "  c_true = Counter(np.argmax(y_train, axis = 1))\n",
        "  print(c_true, \"Actual Distribution of Training Dataset\")\n",
        "  print(model.evaluate(x_train, y_train), \"Training Measures of Model.\")\n",
        "  print(\"Classification Report of Model on Training Data\")\n",
        "  print(classification_report(np.argmax(y_train, axis =1), np.argmax(model.predict(x_train), axis = 1) , digits = 4) )\n",
        "  make_confusion_matrix(confusion_matrix(np.argmax(y_train, axis = 1), np.argmax(model.predict(x_train), axis = 1)))\n",
        "  print(\"\\n------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "  #Validation Data Metrics\n",
        "  print(\"VALIDATION MEASURES: \")\n",
        "  pred_y = model.predict(x_val)\n",
        "  c_pred = Counter(np.argmax(pred_y, axis = 1))\n",
        "  print(c_pred, \"Predicted Distribution of Validation Dataset\")\n",
        "  c_true = Counter(np.argmax(y_val, axis = 1))\n",
        "  print(c_true, \"Actual Distribution of Validation Dataset\")\n",
        "  print(model.evaluate(x_val, y_val), \"Validation Measures of Model.\")\n",
        "  print(\"Classification Report of Model on Validation Data\")\n",
        "  print(classification_report(np.argmax(y_val, axis = 1), np.argmax(model.predict(x_val), axis = 1), digits = 4))\n",
        "  make_confusion_matrix(confusion_matrix(np.argmax(y_val, axis = 1), np.argmax(model.predict(x_val), axis =1)) )\n",
        "  print(\"\\n------------------------------------------------------------------------------------------\\n\")\n",
        "  gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb8M2JsTsT7v"
      },
      "source": [
        "## Model Architecture Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6x9iLrFVq94"
      },
      "source": [
        "METRICS = [\r\n",
        "      keras.metrics.TruePositives(name='tp'),\r\n",
        "      keras.metrics.FalsePositives(name='fp'),\r\n",
        "      keras.metrics.TrueNegatives(name='tn'),\r\n",
        "      keras.metrics.FalseNegatives(name='fn'), \r\n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\r\n",
        "      keras.metrics.Precision(name='precision'),\r\n",
        "      keras.metrics.Recall(name='recall'),\r\n",
        "      keras.metrics.AUC(name='auc'),\r\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dOUyj04Zsqq"
      },
      "source": [
        "def dummy_models(sub_signals=12, metrics = METRICS):\r\n",
        "  sample_size = int(8064/sub_signals)\r\n",
        "  models = [0]*32\r\n",
        "  for i in range(32):\r\n",
        "    models[i] = Sequential()\r\n",
        "    models[i].add(Dense(100, activation = 'relu', input_shape = (sample_size, 1)))\r\n",
        "    models[i].add(Flatten())\r\n",
        "    models[i].add(Dense(40, activation = 'relu'))\r\n",
        "    models[i].add(Dense(2,  activation = 'softmax'))\r\n",
        "    models[i].compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 1e-4) , loss = tf.keras.losses.BinaryCrossentropy(), metrics= metrics)\r\n",
        "  print(\"All models defined.\")\r\n",
        "  return models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlfu_aayoXSl"
      },
      "source": [
        "null_data = np.zeros((13824, 672, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puI2iRNDKpaW"
      },
      "source": [
        "def create_models(dense_par=20, sub_signals=12, metrics = METRICS):\r\n",
        "  sample_size = int(8064/sub_signals)\r\n",
        "  models = [0]*32\r\n",
        "  for i in range(32):\r\n",
        "    models[i] = Sequential()\r\n",
        "    #block 1\r\n",
        "    models[i].add(Conv1D(filters=32, kernel_size=5,strides = 3, input_shape=(sample_size, 1)))\r\n",
        "    models[i].add(BatchNormalization())\r\n",
        "    models[i].add(tf.keras.layers.Activation('relu'))\r\n",
        "    \r\n",
        "    #block 2\r\n",
        "    models[i].add(Conv1D(filters=24, kernel_size=3,strides = 2))\r\n",
        "    models[i].add(BatchNormalization())\r\n",
        "    models[i].add(tf.keras.layers.Activation('relu'))\r\n",
        "    \r\n",
        "    #block 3\r\n",
        "    models[i].add(Conv1D(filters=16, kernel_size=3,strides = 2))\r\n",
        "    models[i].add(BatchNormalization())\r\n",
        "    models[i].add(tf.keras.layers.Activation('relu'))\r\n",
        "    \r\n",
        "    #block 4\r\n",
        "    models[i].add(Conv1D(filters=8, kernel_size=3,strides = 2))\r\n",
        "    models[i].add(BatchNormalization())\r\n",
        "    models[i].add(tf.keras.layers.Activation('relu'))\r\n",
        "    \r\n",
        "    #fc-1\r\n",
        "    models[i].add(Flatten())\r\n",
        "    models[i].add(Dense(dense_par, activation='relu'))\r\n",
        "    \r\n",
        "    #dropout\r\n",
        "    models[i].add(Dropout(rate = 0.5))\r\n",
        "    \r\n",
        "    #fc2 and softmax\r\n",
        "    #binary classification\r\n",
        "    models[i].add(Dense(2,  activation = 'softmax'))\r\n",
        "    models[i].compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 1e-4) , loss = tf.keras.losses.BinaryCrossentropy(), metrics= metrics)\r\n",
        "\r\n",
        "    #mutliclass classification\r\n",
        "    #models[i].add(Dense(4, activation = 'softmax'))\r\n",
        "    #models[i].compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.001) , loss = tf.keras.losses.CategoricalCrossentropy(), metrics= 'accuracy')\r\n",
        "\r\n",
        "  print(\"All models defined.\")\r\n",
        "  return models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wsBgSi2DXIE"
      },
      "source": [
        "## Training using 12 sub_signals per EEG signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8otSyse0WSu"
      },
      "source": [
        "### Without Any modifications to deal with Class Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz2gXqb20nez"
      },
      "source": [
        "# Fresh Start to training with freeing up of RAM\r\n",
        "try:\r\n",
        "  del models\r\n",
        "  del history\r\n",
        "except:\r\n",
        "  print(\"Variables already freed\")\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-khrP8a0ne3"
      },
      "source": [
        "Input Dependent Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGqpi5xi0ne4"
      },
      "source": [
        "baseline_models = dummy_models(sub_signals = 12, metrics = METRICS)\r\n",
        "history = [0]*32\r\n",
        "epochs = 500\r\n",
        "#range will be 32 in actual code\r\n",
        "for j in range(1):\r\n",
        "  print(f'Individual Net : {j+1}')   \r\n",
        "  x_train, x_val, y_train, y_val = train_test_split( X_train_12[j],y_train_12, test_size = 0.1, random_state = 42, shuffle = True, stratify = y_train_12)\r\n",
        "\r\n",
        "  #Input Dependent dummy model\r\n",
        "  history[j] = baseline_models[j].fit(x_train, y_train, batch_size = 2048, epochs = epochs, \\\r\n",
        "                                      validation_data = (x_val, y_val), shuffle = True, verbose = 0)\r\n",
        "  \r\n",
        "  show_metrics(x_train, x_val, y_train, y_val, baseline_models[j])\r\n",
        "  show_test_metrics(x_test_12[j], y_test_12, baseline_models[j])\r\n",
        "  \r\n",
        "  plot_evaluation_curves(history[j], epochs, ('accuracy', 'val_accuracy'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('precision', 'val_precision'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('recall', 'val_recall'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('auc', 'val_auc'))\r\n",
        "  print(\"\\n-----------------------------------------------------------------------------------------\")\r\n",
        "  gc.collect()\r\n",
        "gc.collect()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4Mdf7iK0ne5"
      },
      "source": [
        "# Fresh Start to training with freeing up of RAM\r\n",
        "try:\r\n",
        "  del models\r\n",
        "  del history\r\n",
        "except:\r\n",
        "  print(\"Variables already freed\")\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6OUzkwj0ne6"
      },
      "source": [
        "Input Independent LP 1DCNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4bKRe0E0ne7"
      },
      "source": [
        "models = create_models(dense_par = 20, sub_signals = 12, metrics = METRICS)\r\n",
        "history = [0]*32\r\n",
        "epochs = 500\r\n",
        "#range will be 32 in actual code\r\n",
        "for j in range(1):\r\n",
        "  print(f'Individual Net : {j+1}')   \r\n",
        "  #Null Data generation\r\n",
        "  x_train, x_val, y_train, y_val = train_test_split( null_data,y_train_12, test_size = 0.1, random_state = 42, shuffle = True, stratify = y_train_12)\r\n",
        "  history[j] = models[j].fit(x_train, y_train, batch_size = 2048, epochs = epochs, \\\r\n",
        "                             validation_data = (x_val, y_val), shuffle = True, verbose = 0)\r\n",
        "  \r\n",
        "  show_metrics(x_train, x_val, y_train, y_val, models[j])\r\n",
        "  show_test_metrics(x_test_12[j], y_test_12, models[j])\r\n",
        "  \r\n",
        "  plot_evaluation_curves(history[j], epochs, ('accuracy', 'val_accuracy'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('precision', 'val_precision'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('recall', 'val_recall'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('auc', 'val_auc'))\r\n",
        "  print(\"\\n-----------------------------------------------------------------------------------------\")\r\n",
        "  gc.collect()\r\n",
        "gc.collect()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fqEnBQe0ne9"
      },
      "source": [
        "# Fresh Start to training with freeing up of RAM\r\n",
        "try:\r\n",
        "  del models\r\n",
        "  del history\r\n",
        "except:\r\n",
        "  print(\"Variables already freed\")\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU_FJK270ne-"
      },
      "source": [
        "LP 1DCNN Input Dependent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55hp8MhG0ne_"
      },
      "source": [
        "models = create_models(dense_par = 20, sub_signals = 12, metrics = METRICS)\r\n",
        "history = [0]*32\r\n",
        "epochs = 500\r\n",
        "#range will be 32 in actual code\r\n",
        "for j in range(1):\r\n",
        "  print(f'Individual Net : {j+1}')   \r\n",
        "  x_train, x_val, y_train, y_val = train_test_split( X_train_12[j],y_train_12, test_size = 0.1, random_state = 42, shuffle = True, stratify = y_train_12)\r\n",
        "  #Actual Model Training with real data\r\n",
        "  history[j] = models[j].fit(x_train, y_train, batch_size = 2048, epochs = epochs, validation_data = (x_val, y_val),\\\r\n",
        "                             shuffle = True, verbose = 0)\r\n",
        "  show_metrics(x_train, x_val, y_train, y_val, models[j])\r\n",
        "  show_test_metrics(x_test_12[j], y_test_12, models[j])\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('accuracy', 'val_accuracy'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('precision', 'val_precision'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('recall', 'val_recall'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('auc', 'val_auc'))\r\n",
        "  print(\"\\n-----------------------------------------------------------------------------------------\")\r\n",
        "  gc.collect()\r\n",
        "gc.collect()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJikXdCyl1HT"
      },
      "source": [
        "### With Class Weights set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sS_tgbvu3uO"
      },
      "source": [
        "# Fresh Start to training with freeing up of RAM\r\n",
        "try:\r\n",
        "  del models\r\n",
        "  del history\r\n",
        "except:\r\n",
        "  print(\"Variables already freed\")\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc2ghoPayl1T"
      },
      "source": [
        "Input Dependent Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEt5X3L0ygP7"
      },
      "source": [
        "baseline_models = dummy_models(sub_signals = 12, metrics = METRICS)\r\n",
        "history = [0]*32\r\n",
        "epochs = 500\r\n",
        "#range will be 32 in actual code\r\n",
        "for j in range(1):\r\n",
        "  print(f'Individual Net : {j+1}')   \r\n",
        "  x_train, x_val, y_train, y_val = train_test_split( X_train_12[j],y_train_12, test_size = 0.1, random_state = 42, shuffle = True, stratify = y_train_12)\r\n",
        "\r\n",
        "  #Input Dependent dummy model\r\n",
        "  history[j] = baseline_models[j].fit(x_train, y_train, batch_size = 2048, epochs = epochs, \\\r\n",
        "                                      validation_data = (x_val, y_val),  class_weight = d_bin_class_weights, shuffle = True, verbose = 0)\r\n",
        "  \r\n",
        "  show_metrics(x_train, x_val, y_train, y_val, baseline_models[j])\r\n",
        "  show_test_metrics(x_test_12[j], y_test_12, baseline_models[j])\r\n",
        "\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('accuracy', 'val_accuracy'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('precision', 'val_precision'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('recall', 'val_recall'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('auc', 'val_auc'))\r\n",
        "  print(\"\\n-----------------------------------------------------------------------------------------\")\r\n",
        "  gc.collect()\r\n",
        "gc.collect()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbCzbLxx0G0l"
      },
      "source": [
        "# Fresh Start to training with freeing up of RAM\r\n",
        "try:\r\n",
        "  del models\r\n",
        "  del history\r\n",
        "except:\r\n",
        "  print(\"Variables already freed\")\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VknutiZOyvnM"
      },
      "source": [
        "Input Independent LP 1DCNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyY0oAzeyv0_"
      },
      "source": [
        "models = create_models(dense_par = 20, sub_signals = 12, metrics = METRICS)\r\n",
        "history = [0]*32\r\n",
        "epochs = 500\r\n",
        "#range will be 32 in actual code\r\n",
        "for j in range(1):\r\n",
        "  print(f'Individual Net : {j+1}')   \r\n",
        "  #Null Data generation\r\n",
        "  x_train, x_val, y_train, y_val = train_test_split( null_data,y_train_12, test_size = 0.1, random_state = 42, shuffle = True, stratify = y_train_12)\r\n",
        "  history[j] = models[j].fit(x_train, y_train, batch_size = 2048, epochs = epochs, \\\r\n",
        "                             validation_data = (x_val, y_val),  class_weight = d_bin_class_weights, shuffle = True, verbose = 0)\r\n",
        "  \r\n",
        "  show_metrics(x_train, x_val, y_train, y_val, models[j])\r\n",
        "  show_test_metrics(x_test_12[j], y_test_12, models[j])\r\n",
        "\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('accuracy', 'val_accuracy'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('precision', 'val_precision'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('recall', 'val_recall'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('auc', 'val_auc'))\r\n",
        "  print(\"\\n-----------------------------------------------------------------------------------------\")\r\n",
        "  gc.collect()\r\n",
        "gc.collect()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGHFZrjx0IAk"
      },
      "source": [
        "# Fresh Start to training with freeing up of RAM\r\n",
        "try:\r\n",
        "  del models\r\n",
        "  del history\r\n",
        "except:\r\n",
        "  print(\"Variables already freed\")\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GCYsO2gyorC"
      },
      "source": [
        "LP 1DCNN Input Dependent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKNCgkrsygYq"
      },
      "source": [
        "models = create_models(dense_par = 20, sub_signals = 12, metrics = METRICS)\r\n",
        "history = [0]*32\r\n",
        "epochs = 500\r\n",
        "#range will be 32 in actual code\r\n",
        "for j in range(1):\r\n",
        "  print(f'Individual Net : {j+1}')   \r\n",
        "  x_train, x_val, y_train, y_val = train_test_split( X_train_12[j],y_train_12, test_size = 0.1, random_state = 42, shuffle = True, stratify = y_train_12)\r\n",
        "  #Actual Model Training with real data\r\n",
        "  history[j] = models[j].fit(x_train, y_train, batch_size = 2048, epochs = epochs, validation_data = (x_val, y_val),\\\r\n",
        "                             class_weight = d_bin_class_weights, shuffle = True, verbose = 0)\r\n",
        "  show_metrics(x_train, x_val, y_train, y_val, models[j])\r\n",
        "  show_test_metrics(x_test_12[j], y_test_12, models[j])\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('accuracy', 'val_accuracy'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('precision', 'val_precision'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('recall', 'val_recall'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('auc', 'val_auc'))\r\n",
        "  print(\"\\n-----------------------------------------------------------------------------------------\")\r\n",
        "  gc.collect()\r\n",
        "gc.collect()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY1hA7Y6nhQ0"
      },
      "source": [
        "### With Resampling Done using SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUkTBl25ou3o"
      },
      "source": [
        "# Fresh Start to training with freeing up of RAM\r\n",
        "try:\r\n",
        "  del models\r\n",
        "  del history\r\n",
        "except:\r\n",
        "  print(\"Variables already freed\")\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGMAWIQ_ou3x"
      },
      "source": [
        "Input Dependent Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su3txYXyou3x"
      },
      "source": [
        "baseline_models = dummy_models(sub_signals = 12, metrics = METRICS)\r\n",
        "history = [0]*32\r\n",
        "epochs = 500\r\n",
        "#range will be 32 in actual code\r\n",
        "for j in range(1):\r\n",
        "  print(f'Individual Net : {j+1}')   \r\n",
        "  x_train, x_val, y_train, y_val = train_test_split( X_train_12[j],y_train_12, test_size = 0.1, random_state = 42, shuffle = True, stratify = y_train_12)\r\n",
        "  x_train = x_train.reshape((x_train.shape[0], x_train.shape[1]))\r\n",
        "  y_train = np.argmax(y_train, axis = 1)\r\n",
        "  x_train, y_train = SMOTE(random_state=RANDOM_SEED).fit_resample(x_train,y_train)\r\n",
        "  print(\"Resampled Using SMOTE.\")\r\n",
        "  y_train = np.array(list(map(encode, y_train)))\r\n",
        "  x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\r\n",
        "  #Input Dependent dummy model\r\n",
        "  history[j] = baseline_models[j].fit(x_train, y_train, batch_size = 2048, epochs = epochs, \\\r\n",
        "                                      validation_data = (x_val, y_val), shuffle = True, verbose = 0)\r\n",
        "  \r\n",
        "  show_metrics(x_train, x_val, y_train, y_val, baseline_models[j])\r\n",
        "  show_test_metrics(x_test_12[j], y_test_12, baseline_models[j])\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('accuracy', 'val_accuracy'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('precision', 'val_precision'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('recall', 'val_recall'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('auc', 'val_auc'))\r\n",
        "  print(\"\\n-----------------------------------------------------------------------------------------\")\r\n",
        "  gc.collect()\r\n",
        "gc.collect()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1iMMgR2sSVY"
      },
      "source": [
        "# Fresh Start to training with freeing up of RAM\r\n",
        "try:\r\n",
        "  del models\r\n",
        "  del history\r\n",
        "except:\r\n",
        "  print(\"Variables already freed\")\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_ZXQ17psSVZ"
      },
      "source": [
        "Input Independent LP 1DCNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkFXq14_sSVZ"
      },
      "source": [
        "models = create_models(dense_par = 20, sub_signals = 12, metrics = METRICS)\r\n",
        "history = [0]*32\r\n",
        "epochs = 500\r\n",
        "#range will be 32 in actual code\r\n",
        "for j in range(1):\r\n",
        "  print(f'Individual Net : {j+1}')   \r\n",
        "  #Null Data generation\r\n",
        "  x_train, x_val, y_train, y_val = train_test_split( null_data,y_train_12, test_size = 0.1, random_state = 42, shuffle = True, stratify = y_train_12)\r\n",
        "  x_train = x_train.reshape((x_train.shape[0], x_train.shape[1]))\r\n",
        "  y_train = np.argmax(y_train, axis = 1)\r\n",
        "  x_train, y_train = SMOTE(random_state=RANDOM_SEED).fit_resample(x_train,y_train)\r\n",
        "  print(\"Resampled Using SMOTE.\")\r\n",
        "  y_train = np.array(list(map(encode, y_train)))\r\n",
        "  x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\r\n",
        "\r\n",
        "  history[j] = models[j].fit(x_train, y_train, batch_size = 2048, epochs = epochs, \\\r\n",
        "                             validation_data = (x_val, y_val), shuffle = True, verbose = 0)\r\n",
        "  \r\n",
        "  show_metrics(x_train, x_val, y_train, y_val, models[j])\r\n",
        "  show_test_metrics(x_test_12[j], y_test_12, models[j])\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('accuracy', 'val_accuracy'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('precision', 'val_precision'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('recall', 'val_recall'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('auc', 'val_auc'))\r\n",
        "  print(\"\\n-----------------------------------------------------------------------------------------\")\r\n",
        "  gc.collect()\r\n",
        "gc.collect()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fliejknsSVZ"
      },
      "source": [
        "# Fresh Start to training with freeing up of RAM\r\n",
        "try:\r\n",
        "  del models\r\n",
        "  del history\r\n",
        "except:\r\n",
        "  print(\"Variables already freed\")\r\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2Q0BiEasSVa"
      },
      "source": [
        "LP 1DCNN Input Dependent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VY8fqupsSVa"
      },
      "source": [
        "models = create_models(dense_par = 20, sub_signals = 12, metrics = METRICS)\r\n",
        "history = [0]*32\r\n",
        "epochs = 500\r\n",
        "#range will be 32 in actual code\r\n",
        "for j in range(1):\r\n",
        "  print(f'Individual Net : {j+1}')   \r\n",
        "  x_train, x_val, y_train, y_val = train_test_split( X_train_12[j],y_train_12, test_size = 0.1, random_state = 42, shuffle = True, stratify = y_train_12)\r\n",
        "  x_train = x_train.reshape((x_train.shape[0], x_train.shape[1]))\r\n",
        "  y_train = np.argmax(y_train, axis = 1)\r\n",
        "  x_train, y_train = SMOTE(random_state=RANDOM_SEED).fit_resample(x_train,y_train)\r\n",
        "  print(\"Resampled Using SMOTE.\")\r\n",
        "  y_train = np.array(list(map(encode, y_train)))\r\n",
        "  x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\r\n",
        "  #Actual Model Training with real data\r\n",
        "  history[j] = models[j].fit(x_train, y_train, batch_size = 2048, \\\r\n",
        "                             epochs = epochs, validation_data = (x_val, y_val), shuffle = True, verbose = 0)\r\n",
        "  show_metrics(x_train, x_val, y_train, y_val, models[j])\r\n",
        "  show_test_metrics(x_test_12[j], y_test_12, models[j])\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('accuracy', 'val_accuracy'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('precision', 'val_precision'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('recall', 'val_recall'))\r\n",
        "  plot_evaluation_curves(history[j], epochs, ('auc', 'val_auc'))\r\n",
        "  print(\"\\n-----------------------------------------------------------------------------------------\")\r\n",
        "  gc.collect()\r\n",
        "gc.collect()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_aoIKbpK1xY"
      },
      "source": [
        "# Ensemble Algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVqmg5fVK4cA"
      },
      "source": [
        "#loop over test instances i.e. 128\r\n",
        "  #loop over 32 channels i.e. 1 model for each channel\r\n",
        "    #for each channel, pass the shape (sub_singals,samples,1) to M(i), here sub_signals will be the batch_size\r\n",
        "    #get all predictions for a single channel's all samples, take their mode. This is the prediction for that channel\r\n",
        "    #store all the channels' predicitions in an array\r\n",
        "  #take mode for all channels' predictions from array, this is the predicted value for that instance"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}